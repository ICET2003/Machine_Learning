{
 "cells": [
  {
   "cell_type": "raw",
   "id": "110bdbb5-cfbb-4d0a-8303-34c637b2e866",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"In-Class Assignment 6\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    embed-resources: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99710dd2-2808-434a-a193-914a79926d05",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    "- For questions that require coding, you need to write the relevant code and display its output. Your output should either be the direct answer to the question or clearly display the answer in it.\n",
    "- For questions that require a written answer (sometimes along with the code), you need to put your answer in a Markdown cell. Writing the answer as a comment or as a print line is not acceptable.\n",
    "- You need to render this file as HTML using Quarto and submit the HTML file. **Please note that this is a requirement and not optional.** A submission cannot be graded until it is properly rendered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d3ac5-4a45-41c6-affe-b6c9ae0499ca",
   "metadata": {},
   "source": [
    "Import all the libraries and tools you need below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b70dd4-f1c4-4196-ae10-3631c1b76c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries/packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, hamming_loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, ShuffleSplit\n",
    "from sklearn.svm import SVC, SVR, LinearSVC, LinearSVR\n",
    "# import random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# Imoport the feature for multi-label regression\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor, ClassifierChain\n",
    "from sklearn.datasets import make_multilabel_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d26fe-8221-4b90-a300-f2db075cf26e",
   "metadata": {},
   "source": [
    "### 1)\n",
    "\n",
    "Read the data from **X_train.csv**, **y_train.csv**, **X_test.csv**, and **y_test.csv**. The predictors (X's) are rhythmic and timbre features extracted from a number of songs. The responses (y's) are the emotion class labels for each song. **(2.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2065c9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_Centroid', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_Rolloff', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_Flux', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_MFCC_0', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_MFCC_1', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_MFCC_2', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_MFCC_3', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_MFCC_4', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_MFCC_5', 'NUMERIC')</th>\n",
       "      <th>('Mean_Acc1298_Mean_Mem40_MFCC_6', 'NUMERIC')</th>\n",
       "      <th>...</th>\n",
       "      <th>('Std_Acc1298_Std_Mem40_MFCC_11', 'NUMERIC')</th>\n",
       "      <th>('Std_Acc1298_Std_Mem40_MFCC_12', 'NUMERIC')</th>\n",
       "      <th>('BH_LowPeakAmp', 'NUMERIC')</th>\n",
       "      <th>('BH_LowPeakBPM', 'NUMERIC')</th>\n",
       "      <th>('BH_HighPeakAmp', 'NUMERIC')</th>\n",
       "      <th>('BH_HighPeakBPM', 'NUMERIC')</th>\n",
       "      <th>('BH_HighLowRatio', 'NUMERIC')</th>\n",
       "      <th>('BHSUM1', 'NUMERIC')</th>\n",
       "      <th>('BHSUM2', 'NUMERIC')</th>\n",
       "      <th>('BHSUM3', 'NUMERIC')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034741</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>0.091225</td>\n",
       "      <td>-73.302422</td>\n",
       "      <td>6.215179</td>\n",
       "      <td>0.615074</td>\n",
       "      <td>2.037160</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>1.301409</td>\n",
       "      <td>0.558576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118630</td>\n",
       "      <td>0.094923</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.245457</td>\n",
       "      <td>0.105065</td>\n",
       "      <td>0.405399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081374</td>\n",
       "      <td>0.272747</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>-62.584437</td>\n",
       "      <td>3.183163</td>\n",
       "      <td>-0.218145</td>\n",
       "      <td>0.163038</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>0.458514</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070075</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.295031</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.276366</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.343547</td>\n",
       "      <td>0.276366</td>\n",
       "      <td>0.710924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110545</td>\n",
       "      <td>0.273567</td>\n",
       "      <td>0.084410</td>\n",
       "      <td>-65.235325</td>\n",
       "      <td>2.794964</td>\n",
       "      <td>0.639047</td>\n",
       "      <td>1.281297</td>\n",
       "      <td>0.757896</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.627636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079917</td>\n",
       "      <td>0.085821</td>\n",
       "      <td>0.161574</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>183.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.188693</td>\n",
       "      <td>0.045941</td>\n",
       "      <td>0.457372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042481</td>\n",
       "      <td>0.199281</td>\n",
       "      <td>0.093447</td>\n",
       "      <td>-80.305152</td>\n",
       "      <td>5.824409</td>\n",
       "      <td>0.648848</td>\n",
       "      <td>1.754870</td>\n",
       "      <td>1.495532</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>0.809644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129145</td>\n",
       "      <td>0.122330</td>\n",
       "      <td>0.043012</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.206562</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.102839</td>\n",
       "      <td>0.241934</td>\n",
       "      <td>0.351009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074550</td>\n",
       "      <td>0.140880</td>\n",
       "      <td>0.079789</td>\n",
       "      <td>-93.697749</td>\n",
       "      <td>5.543229</td>\n",
       "      <td>1.064262</td>\n",
       "      <td>0.899152</td>\n",
       "      <td>0.890336</td>\n",
       "      <td>0.702328</td>\n",
       "      <td>0.490685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284196</td>\n",
       "      <td>0.189988</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.144039</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.195196</td>\n",
       "      <td>0.310801</td>\n",
       "      <td>0.683817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ('Mean_Acc1298_Mean_Mem40_Centroid', 'NUMERIC')  \\\n",
       "0                                         0.034741   \n",
       "1                                         0.081374   \n",
       "2                                         0.110545   \n",
       "3                                         0.042481   \n",
       "4                                         0.074550   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_Rolloff', 'NUMERIC')  \\\n",
       "0                                        0.089665   \n",
       "1                                        0.272747   \n",
       "2                                        0.273567   \n",
       "3                                        0.199281   \n",
       "4                                        0.140880   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_Flux', 'NUMERIC')  \\\n",
       "0                                     0.091225   \n",
       "1                                     0.085733   \n",
       "2                                     0.084410   \n",
       "3                                     0.093447   \n",
       "4                                     0.079789   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_MFCC_0', 'NUMERIC')  \\\n",
       "0                                     -73.302422   \n",
       "1                                     -62.584437   \n",
       "2                                     -65.235325   \n",
       "3                                     -80.305152   \n",
       "4                                     -93.697749   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_MFCC_1', 'NUMERIC')  \\\n",
       "0                                       6.215179   \n",
       "1                                       3.183163   \n",
       "2                                       2.794964   \n",
       "3                                       5.824409   \n",
       "4                                       5.543229   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_MFCC_2', 'NUMERIC')  \\\n",
       "0                                       0.615074   \n",
       "1                                      -0.218145   \n",
       "2                                       0.639047   \n",
       "3                                       0.648848   \n",
       "4                                       1.064262   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_MFCC_3', 'NUMERIC')  \\\n",
       "0                                       2.037160   \n",
       "1                                       0.163038   \n",
       "2                                       1.281297   \n",
       "3                                       1.754870   \n",
       "4                                       0.899152   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_MFCC_4', 'NUMERIC')  \\\n",
       "0                                       0.804065   \n",
       "1                                       0.620251   \n",
       "2                                       0.757896   \n",
       "3                                       1.495532   \n",
       "4                                       0.890336   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_MFCC_5', 'NUMERIC')  \\\n",
       "0                                       1.301409   \n",
       "1                                       0.458514   \n",
       "2                                       0.489412   \n",
       "3                                       0.739909   \n",
       "4                                       0.702328   \n",
       "\n",
       "   ('Mean_Acc1298_Mean_Mem40_MFCC_6', 'NUMERIC')  ...  \\\n",
       "0                                       0.558576  ...   \n",
       "1                                       0.041426  ...   \n",
       "2                                       0.627636  ...   \n",
       "3                                       0.809644  ...   \n",
       "4                                       0.490685  ...   \n",
       "\n",
       "   ('Std_Acc1298_Std_Mem40_MFCC_11', 'NUMERIC')  \\\n",
       "0                                      0.118630   \n",
       "1                                      0.070075   \n",
       "2                                      0.079917   \n",
       "3                                      0.129145   \n",
       "4                                      0.284196   \n",
       "\n",
       "   ('Std_Acc1298_Std_Mem40_MFCC_12', 'NUMERIC')  ('BH_LowPeakAmp', 'NUMERIC')  \\\n",
       "0                                      0.094923                      0.051035   \n",
       "1                                      0.041565                      0.295031   \n",
       "2                                      0.085821                      0.161574   \n",
       "3                                      0.122330                      0.043012   \n",
       "4                                      0.189988                      0.029308   \n",
       "\n",
       "   ('BH_LowPeakBPM', 'NUMERIC')  ('BH_HighPeakAmp', 'NUMERIC')  \\\n",
       "0                          68.0                       0.014937   \n",
       "1                          70.0                       0.276366   \n",
       "2                          61.0                       0.000000   \n",
       "3                          66.0                       0.206562   \n",
       "4                         100.0                       0.144039   \n",
       "\n",
       "   ('BH_HighPeakBPM', 'NUMERIC')  ('BH_HighLowRatio', 'NUMERIC')  \\\n",
       "0                          136.0                             2.0   \n",
       "1                          140.0                             2.0   \n",
       "2                          183.0                             3.0   \n",
       "3                          132.0                             2.0   \n",
       "4                          200.0                             2.0   \n",
       "\n",
       "   ('BHSUM1', 'NUMERIC')  ('BHSUM2', 'NUMERIC')  ('BHSUM3', 'NUMERIC')  \n",
       "0               0.245457               0.105065               0.405399  \n",
       "1               0.343547               0.276366               0.710924  \n",
       "2               0.188693               0.045941               0.457372  \n",
       "3               0.102839               0.241934               0.351009  \n",
       "4               0.195196               0.310801               0.683817  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from all dataset\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "\n",
    "# Check data\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248b908-7e11-45cb-8ac4-e511eb13555c",
   "metadata": {},
   "source": [
    "### 2)\n",
    "\n",
    "Print the first five rows of either `y_train` or `y_test`. You should observe that each observation has multiple class labels and it is possible for an observation to have multiple Class 1 values.\n",
    "\n",
    "**(2.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a6c0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('amazed-suprised', ['0', '1'])</th>\n",
       "      <th>('happy-pleased', ['0', '1'])</th>\n",
       "      <th>('relaxing-calm', ['0', '1'])</th>\n",
       "      <th>('quiet-still', ['0', '1'])</th>\n",
       "      <th>('sad-lonely', ['0', '1'])</th>\n",
       "      <th>('angry-aggresive', ['0', '1'])</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ('amazed-suprised', ['0', '1'])  ('happy-pleased', ['0', '1'])  \\\n",
       "0                                0                              1   \n",
       "1                                1                              0   \n",
       "2                                0                              1   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "\n",
       "   ('relaxing-calm', ['0', '1'])  ('quiet-still', ['0', '1'])  \\\n",
       "0                              1                            0   \n",
       "1                              0                            0   \n",
       "2                              0                            0   \n",
       "3                              1                            0   \n",
       "4                              0                            1   \n",
       "\n",
       "   ('sad-lonely', ['0', '1'])  ('angry-aggresive', ['0', '1'])  \n",
       "0                           0                                0  \n",
       "1                           0                                1  \n",
       "2                           0                                1  \n",
       "3                           0                                0  \n",
       "4                           0                                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first five rows of y_train or y_test\n",
    "y_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83356816",
   "metadata": {},
   "source": [
    "There are totally 6 responses per observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb499d1-ee01-4285-8ac3-a068e4f7dd99",
   "metadata": {},
   "source": [
    "### 3)\n",
    "\n",
    "Create a [Random Forest Classifier](https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html). Use 500 trees, so that its variance is reduced adequately. Leave all the other hyperparameters default; tuning their values does not change the results substantially. Use `random_state=2` for reproducibility. **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61eeb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest (rf) classifier/ set at 500 trees \n",
    "random_forest = RandomForestClassifier(n_estimators = 500, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7b333-22f7-4868-83ad-3acdfa4ebc64",
   "metadata": {},
   "source": [
    "### 4)\n",
    "\n",
    "Train the Random Forest on the multi-label data using the **Binary Relevance** approach. You need to check the [scikit-learn documentation](https://scikit-learn.org/stable/api/sklearn.multioutput.html) for the correct object and its usage.\n",
    "\n",
    "Evaluate the multi-label classifier on the test data, using [Hamming Loss](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.hamming_loss.html).\n",
    "\n",
    "**(15 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8931fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Relevance Approach\n",
    "\n",
    "# Change all dataframe to array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Get the model workflow for classification\n",
    "binary_relevance_rf = MultiOutputClassifier(random_forest).fit(X_train, y_train)\n",
    "\n",
    "# Predict the value of y based on X_test\n",
    "y_pred = binary_relevance_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bddab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19636963696369636"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the cost using hamming loss\n",
    "hammingloss_binary = hamming_loss(y_test, y_pred)\n",
    "\n",
    "# Print out\n",
    "hammingloss_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffaf0c-db26-4d10-bb2b-d552012321e4",
   "metadata": {},
   "source": [
    "### 5)\n",
    "\n",
    "What does the Hamming Loss represent in terms of what the model predicts right/wrong? **(10 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf03186",
   "metadata": {},
   "source": [
    "Hamming loss represents the fraction of labels that are incorrectly predicted across all observations. Therefore, the model with higher hamming loss predicts more wrong results while the model with lower hamming loss guarantees that it will accurately predict the classes of responses. The model is perfect if hamming loss = 0. \n",
    "\n",
    "In this dataset, out of $391 * 6 = 2346$ labels of responses, the model incorrectly predicts $2346 * 0.1964 \\approx 461$ of them and rightly predicts $2346 - 461 = 1885$ of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03ae2b-b7f5-4937-8c97-ccb122a0fb73",
   "metadata": {},
   "source": [
    "### 6)\n",
    "\n",
    "Train the Random Forest on the multi-label data using the **Classifier Chain** approach. Keep all the inputs (other than the base model) default. You may need to refer back to the scikit-learn documentation for the correct object.\n",
    "\n",
    "Evaluate the multi-label classifier on the test data, using Hamming Loss. You should see the same performance as Question 4.\n",
    "\n",
    "**(15 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489aff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier chain method\n",
    "\n",
    "# Create a classifier chain model\n",
    "classifier_chain_rf = ClassifierChain(random_forest, random_state = 2)\n",
    "\n",
    "# Get the y_pred output\n",
    "y_pred = classifier_chain_rf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3cb3084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19554455445544555"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Hamming loss\n",
    "hammingloss_chain = hamming_loss(y_test, y_pred)\n",
    "\n",
    "# Print out\n",
    "hammingloss_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e1e206",
   "metadata": {},
   "source": [
    "The performance of both model created through two different methods are very close to the same. Both of them have the hamming loss at approximately 0.196."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48e687-85bb-48a3-977e-d3595a8ed40d",
   "metadata": {},
   "source": [
    "### 7)\n",
    "\n",
    "Using the scikit-learn documentation, answer the following about the multi-label model in Question 6:\n",
    "\n",
    "- Are you using the true or the predicted classes from the previous classifier(s) as the predictors of the next classifier in the chain?\n",
    "- What is the order of class variables that you use for the chain?\n",
    "\n",
    "**(10 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a3cf0",
   "metadata": {},
   "source": [
    "Based on scikitlearn API, we apply the predicted classes from the previous classifiers as the predictors of the next classification process in the chain. This is sesible since the true classes of responses should not be known for the prediction problems.\n",
    "\n",
    "The order of class variable I apply for my model is $None$ which basically sets the order for chain processing to the order of columns in label matrix Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f1998-e56f-4e21-85ec-17abd4b20eb9",
   "metadata": {},
   "source": [
    "### 8)\n",
    "\n",
    "Repeat Question 6, only with `cv=5` as another input to the Classifier Chain. What does this change about the multi-label model?\n",
    "\n",
    "You should see a slightly lower performance. Why is this a more realistic evaluation of the model?\n",
    "\n",
    "**(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665031d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1971947194719472"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier chain method\n",
    "\n",
    "# Create a classifier chain model, add cv = 5\n",
    "classifier_chain_rf = ClassifierChain(random_forest, cv = 5, random_state = 2)\n",
    "\n",
    "# Get the y_pred output\n",
    "y_pred = classifier_chain_rf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Find Hamming loss\n",
    "hammingloss_chain_updated = hamming_loss(y_test, y_pred)\n",
    "\n",
    "# Print out\n",
    "hammingloss_chain_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b29c1",
   "metadata": {},
   "source": [
    "Hamming loss turns out to be higher because, with cross validation, the size of training dataset is bigger than the one after cross validation (With five folds, the size of training set sinks down to 80%). The more training data to work on let the classifier chain without cv performs better. \n",
    "\n",
    "In reality, the slightly smaller dataset of classifier chain with cv symbolizes the unseen and incomplete label dependencies during training period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e74ca7-1b45-4249-9675-20e1e9cebcaa",
   "metadata": {},
   "source": [
    "### 9)\n",
    "\n",
    "Run the given cell below. It calculates and prints the Variation Inflation Factor (VIF) of each class variable.\n",
    "\n",
    "VIF is a way to aggregate the multi-collinearity each variable has with all the other variables. The higher the VIF value of a variable is, the higher its total correlation is with all the other variables. **Note that having a correlation/multi-collinearity with other variables means carrying some information about other variables.**\n",
    "\n",
    "**(0 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd666f0f-0c72-4e2c-8ac1-25f7e718105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature        VIF\n",
      "0                            const  10.591750\n",
      "1  ('amazed-suprised', ['0', '1'])   1.434148\n",
      "2    ('happy-pleased', ['0', '1'])   1.676727\n",
      "3    ('relaxing-calm', ['0', '1'])   1.782708\n",
      "4      ('quiet-still', ['0', '1'])   1.630620\n",
      "5       ('sad-lonely', ['0', '1'])   1.623160\n",
      "6  ('angry-aggresive', ['0', '1'])   2.126801\n"
     ]
    }
   ],
   "source": [
    "# Change y_train back to dataframe\n",
    "y_train = pd.DataFrame(y_train)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "y = add_constant(y_train)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = y.columns\n",
    "\n",
    "for i in range(len(y.columns)):\n",
    "    vif_data.loc[i,'VIF'] = variance_inflation_factor(y.values, i)\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a6add-81c1-4819-a5e3-91ca4af791c5",
   "metadata": {},
   "source": [
    "### 10)\n",
    "\n",
    "Using the output of Question 9, repeat Question 8, only this time with the **most informative** order of the class variables. (Python starts counting from zero.)\n",
    "\n",
    "You should see the best model performance in this assignment. Why is this the case?\n",
    "\n",
    "**(15 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccd57409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19389438943894388"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier chain method, order specified\n",
    "\n",
    "# Create a classifier chain model, add cv = 5\n",
    "classifier_chain_rf = ClassifierChain(random_forest, order = [5,2,1,3,4,0], cv = 5, random_state = 2)\n",
    "\n",
    "# Get the y_pred output\n",
    "y_pred = classifier_chain_rf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Find Hamming loss\n",
    "hammingloss_chain_updated = hamming_loss(y_test, y_pred)\n",
    "\n",
    "# Print out\n",
    "hammingloss_chain_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b7263",
   "metadata": {},
   "source": [
    "This model will perform best since its first variable applied for the first prediction, which will be used along the chain, carries a significant amount of information. The more information received from predictors, the more accurate predictions can be. Thus, the most informative arrangement of class variables optimizes the available data for model construction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364b6b6-8e41-4773-8837-e0c83dac8b54",
   "metadata": {},
   "source": [
    "### 11)\n",
    "\n",
    "Finally, using the predictions of the best Classifier Chain (from Question 10), calculate and print the test accuracy of the model **for each emotion**. Which emotions are predicted the most and least accurately?\n",
    "\n",
    "**(15 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d97fb20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ('amazed-suprised', ['0', '1']):0.8119\n",
      "Accuracy of ('happy-pleased', ['0', '1']):0.7822\n",
      "Accuracy of ('relaxing-calm', ['0', '1']):0.7376\n",
      "Accuracy of ('quiet-still', ['0', '1']):0.8663\n",
      "Accuracy of ('sad-lonely', ['0', '1']):0.7921\n",
      "Accuracy of ('angry-aggresive', ['0', '1']):0.8465\n"
     ]
    }
   ],
   "source": [
    "# Change y_pred to dataframe\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "emotion = y_test.columns\n",
    "# Get the accuracy\n",
    "for i in range(6):\n",
    "    print(f\"Accuracy of {emotion[i]}:{accuracy_score(y_test.iloc[:,i], y_pred[i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bf359",
   "metadata": {},
   "source": [
    "The emotion 'quite-still' has highest accuracy at 0.8663. On the other hand, the genre with lowest accuracy is relaxing-calm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
