{
 "cells": [
  {
   "cell_type": "raw",
   "id": "00ae08b3-bcad-4c82-ad2e-ebea502b126a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"In-Class Assignment 4\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    embed-resources: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11788c-cabb-4ebb-94b5-c997e05a973d",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    "- For questions that require coding, you need to write the relevant code and display its output. Your output should either be the direct answer to the question or clearly display the answer in it.\n",
    "- For questions that require a written answer (sometimes along with the code), you need to put your answer in a Markdown cell. Writing the answer as a comment or as a print line is not acceptable.\n",
    "- You need to render this file as HTML using Quarto and submit the HTML file. **Please note that this is a requirement and not optional.** A submission cannot be graded until it is properly rendered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb47beb-d819-4ad4-8a0c-33ea8969aaa4",
   "metadata": {},
   "source": [
    "Import all the libraries and tools you need below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c491ada3-5bd4-4ea0-baad-0dacd364d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all reqiored libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold, cross_val_predict, cross_val_score\n",
    "from sklearn.svm import SVC, LinearSVC, SVR, LinearSVR\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, mean_absolute_error, mean_squared_error, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb1ab0-153e-471d-aa21-fc483d6b617e",
   "metadata": {},
   "source": [
    "## 1)\n",
    "\n",
    "In this assignment, you will use the **creditcard.csv** file. Each observation is a credit card transaction. Most of the variables are created by a dimensionality reduction method called Principle Component Analysis (PCA), which will be covered in Week 5 or 6. The `Class` values are stored in the last variable and represent whether the transaction is a regular (0) or fraudulent (1) transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185a27d-6f93-4fd2-8191-d63e6bb349df",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "Read the data. Print the number of Class 0 and Class 1 observations. You should see that there is a class imbalance. **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aab069f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 284315.\n",
      "Class 1: 492\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "credit_card = pd.read_csv(\"creditcard.csv\")\n",
    "# Check the data\n",
    "credit_card.head()\n",
    "# Check class imbalance\n",
    "print(f\"Class 0: {credit_card['Class'].value_counts()[0]}.\")\n",
    "print(f\"Class 1: {credit_card['Class'].value_counts()[1]}\")\n",
    "\n",
    "# There is a severe class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c61d43-99e3-4aff-be4f-ffe4a871a93b",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "There are different methods to handle the class imbalance in the dataset at hand. In this assignment, you will undersample the majority class.\n",
    "\n",
    "There are built-in functions for undersampling in specialized libraries, such as [imblearn](https://imbalanced-learn.org/stable/), which is not installed in Anaconda by default. To make this step reproducible, you will use a more low-level approach with pandas:\n",
    "\n",
    "- Separate the regular (0) and fraudulent (1) observations into two different DataFrames by filtering.\n",
    "- Sample 1000 observations from the DataFrame with the majority class. Use `.sample` method with `random_state=2`.\n",
    "- Concatenate the undersampled majority class DataFrame and the minority class DataFrame.\n",
    "\n",
    "**(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2267b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284315, 31)\n",
      "(492, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188671</th>\n",
       "      <td>128077.0</td>\n",
       "      <td>-3.288944</td>\n",
       "      <td>-4.809848</td>\n",
       "      <td>-1.231524</td>\n",
       "      <td>6.041078</td>\n",
       "      <td>-1.948400</td>\n",
       "      <td>1.772856</td>\n",
       "      <td>2.177367</td>\n",
       "      <td>0.561664</td>\n",
       "      <td>-1.859951</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352295</td>\n",
       "      <td>0.869342</td>\n",
       "      <td>2.760665</td>\n",
       "      <td>-0.514612</td>\n",
       "      <td>0.114622</td>\n",
       "      <td>0.531044</td>\n",
       "      <td>-0.533325</td>\n",
       "      <td>-0.548096</td>\n",
       "      <td>1206.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190546</th>\n",
       "      <td>128878.0</td>\n",
       "      <td>2.020493</td>\n",
       "      <td>-1.000658</td>\n",
       "      <td>-1.039495</td>\n",
       "      <td>-0.453275</td>\n",
       "      <td>-0.737034</td>\n",
       "      <td>-0.433760</td>\n",
       "      <td>-0.587955</td>\n",
       "      <td>-0.148476</td>\n",
       "      <td>-0.491796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.619987</td>\n",
       "      <td>-0.041074</td>\n",
       "      <td>-0.264674</td>\n",
       "      <td>-0.025601</td>\n",
       "      <td>0.910031</td>\n",
       "      <td>-0.051887</td>\n",
       "      <td>-0.063195</td>\n",
       "      <td>67.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46318</th>\n",
       "      <td>42728.0</td>\n",
       "      <td>0.883694</td>\n",
       "      <td>-0.761362</td>\n",
       "      <td>0.928801</td>\n",
       "      <td>1.389779</td>\n",
       "      <td>-0.730351</td>\n",
       "      <td>1.228938</td>\n",
       "      <td>-0.771123</td>\n",
       "      <td>0.432439</td>\n",
       "      <td>1.196648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>-0.104183</td>\n",
       "      <td>-0.321204</td>\n",
       "      <td>-0.812608</td>\n",
       "      <td>0.547630</td>\n",
       "      <td>-0.273658</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.039590</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267636</th>\n",
       "      <td>162855.0</td>\n",
       "      <td>-0.072377</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>-2.211240</td>\n",
       "      <td>-2.153156</td>\n",
       "      <td>3.556343</td>\n",
       "      <td>2.781633</td>\n",
       "      <td>1.142571</td>\n",
       "      <td>0.602748</td>\n",
       "      <td>-0.561615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256899</td>\n",
       "      <td>0.796234</td>\n",
       "      <td>-0.159167</td>\n",
       "      <td>0.752505</td>\n",
       "      <td>-0.263957</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.406915</td>\n",
       "      <td>0.263924</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189610</th>\n",
       "      <td>128481.0</td>\n",
       "      <td>-0.264285</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>-0.643148</td>\n",
       "      <td>-0.984799</td>\n",
       "      <td>0.813840</td>\n",
       "      <td>0.033159</td>\n",
       "      <td>0.536661</td>\n",
       "      <td>0.483326</td>\n",
       "      <td>-0.368426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246360</td>\n",
       "      <td>-0.708310</td>\n",
       "      <td>-0.024761</td>\n",
       "      <td>-1.457310</td>\n",
       "      <td>-0.325381</td>\n",
       "      <td>0.213825</td>\n",
       "      <td>0.115022</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "188671  128077.0 -3.288944 -4.809848 -1.231524  6.041078 -1.948400  1.772856   \n",
       "190546  128878.0  2.020493 -1.000658 -1.039495 -0.453275 -0.737034 -0.433760   \n",
       "46318    42728.0  0.883694 -0.761362  0.928801  1.389779 -0.730351  1.228938   \n",
       "267636  162855.0 -0.072377  0.735400 -2.211240 -2.153156  3.556343  2.781633   \n",
       "189610  128481.0 -0.264285  0.990040 -0.643148 -0.984799  0.813840  0.033159   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "188671  2.177367  0.561664 -1.859951  ...  1.352295  0.869342  2.760665   \n",
       "190546 -0.587955 -0.148476 -0.491796  ...  0.024865  0.619987 -0.041074   \n",
       "46318  -0.771123  0.432439  1.196648  ... -0.036445 -0.104183 -0.321204   \n",
       "267636  1.142571  0.602748 -0.561615  ...  0.256899  0.796234 -0.159167   \n",
       "189610  0.536661  0.483326 -0.368426  ... -0.246360 -0.708310 -0.024761   \n",
       "\n",
       "             V24       V25       V26       V27       V28   Amount  Class  \n",
       "188671 -0.514612  0.114622  0.531044 -0.533325 -0.548096  1206.14      0  \n",
       "190546 -0.264674 -0.025601  0.910031 -0.051887 -0.063195    67.95      0  \n",
       "46318  -0.812608  0.547630 -0.273658  0.055533  0.039590   150.00      0  \n",
       "267636  0.752505 -0.263957  0.108374  0.406915  0.263924    24.00      0  \n",
       "189610 -1.457310 -0.325381  0.213825  0.115022  0.010990    14.28      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply undersampling\n",
    "\n",
    "# Separate the dataframe by applying filtering\n",
    "credit_card_0 = credit_card.loc[credit_card['Class'] == 0]\n",
    "credit_card_1 = credit_card.loc[credit_card['Class'] == 1]\n",
    "print(credit_card_0.shape)\n",
    "print(credit_card_1.shape)\n",
    "\n",
    "# Sample 1000 observations from dataframe with majority of class (Class = 0)\n",
    "credit_card_0_sample = credit_card_0.sample(n = 1000, random_state = 2)\n",
    "\n",
    "# Concatenate the credit card class = 0 with class = 1 \n",
    "credit_card_combined = pd.concat([credit_card_0_sample, credit_card_1], axis = 0)\n",
    "credit_card_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48ca86-5735-4d6b-b38b-d944b8fdf85f",
   "metadata": {},
   "source": [
    "### c)\n",
    "\n",
    "Drop the `Amount` and `Time` variables. The rest of the variables (except `Class`) are the predictors.\n",
    "\n",
    "Create the training and test sets with a 70%-30% split and `random_state=0`. **Stratify the data.**\n",
    "\n",
    "**Note:** Since the PCA-created predictor values are all in the same order of magnitude, scaling is not necessary.\n",
    "\n",
    "**(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "113510b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the amount and time variables\n",
    "credit_card_combined = credit_card_combined.drop(['Amount', 'Time'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f7176c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = credit_card_combined.drop(['Class'], axis = 1) # Predictors\n",
    "y = credit_card_combined['Class'] # Response\n",
    "\n",
    "# Split data (70-30, stratify = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify = y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea264ec-943f-4120-9af6-20c0212cbfd4",
   "metadata": {},
   "source": [
    "## 2)\n",
    "\n",
    "After preprocessing the data, you will tune and train a **linear** Support Vector Machine (SVM) classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3070c9-3d83-4513-a0be-68533fb5f596",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "Create a **linear** SVM classifier. Its training algorithm has some random processes, so keep `random_state=1`. You will need some prediction probabilities, which is not in the original training algorithm of an SVM. To use the extended version of the algorithm, use `probability=True`. **(5 points)**\n",
    "\n",
    "**Note:** Use `SVC`, you will use `LinearSVC` in the next in-class assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b2d48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear SVM classifier\n",
    "SVM_model = SVC(kernel= 'linear', random_state= 1, probability= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a260d0-6be1-460c-8501-dd031ce6d0d5",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "Tune the model with the following specifications:\n",
    "\n",
    "- For the grid of the **only hyperparameter**, use $10^i$ where i is an integer between -4 and 3 (inclusive).\n",
    "- Keep your folds **stratified**. In the same object, also `shuffle` the data with `random_state=15`.\n",
    "- Use both accuracy and recall as your scoring metric, but recall should be the primary (`refit`) metric to find the best hyperparameter.\n",
    "\n",
    "Print the best hyperparameter value and the cross-validation (CV) recall score. (Both can be returned with the attributes of a `GridSearchCV` object.)\n",
    "\n",
    "**Note:** This should take 3-4 minutes to run. You can use the given lines to keep track of the elapsed time. (You do not have to and you can delete those lines if you wish.)\n",
    "\n",
    "**(20 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43b92b30-961e-4d91-865e-71cdfd21fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyperparameter: {'C': 1000}.\n",
      "Recall Score: 0.9013213981244672.\n",
      "Elapsed Time:  1.9050789992014567 minutes.\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "########## YOUR CODE HERE #############\n",
    "\n",
    "# Create a hyperparameter grid\n",
    "C_grid = {'C': [10 ** i for i in range(-4,4)]}\n",
    "\n",
    "# Create a KFold object (Usin) with StratifiedKfold\n",
    "cv_settings = StratifiedKFold(n_splits= 5, shuffle= True, random_state= 15)\n",
    "\n",
    "# Create a CV object\n",
    "gscv = GridSearchCV(SVM_model, C_grid, cv= cv_settings, scoring= ['accuracy', 'recall'], refit= 'recall', n_jobs= -1)\n",
    "\n",
    "# Fit the gscv model with data\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparams and recall score\n",
    "print(f\"Optimal Hyperparameter: {gscv.best_params_}.\")\n",
    "print(f\"Recall Score: {gscv.best_score_}.\")\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "toc = time.time()\n",
    "print('Elapsed Time: ', (toc-tic)/60, 'minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816b9a17-4982-4136-89d5-64cf7854916a",
   "metadata": {},
   "source": [
    "### c)\n",
    "\n",
    "Print the `cv_results_` as a DataFrame to get more insight about the cross-validation process. Print only three columns: (1) the hyperparameter values, (2) the average cross-validation accuracy and (3) the average cross-validation recall.\n",
    "\n",
    "- Did the model sacrifice some accuracy to maximize the recall or is the accuracy increasing with the recall?\n",
    "- What probability threshold do these accuracy and recall values correspond to?\n",
    "\n",
    "**Note:** The column names can be a bit misleading - there are not any test results here, only average cross-validation results.\n",
    "\n",
    "**(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0905eaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.926265</td>\n",
       "      <td>0.776343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.939676</td>\n",
       "      <td>0.817050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.948293</td>\n",
       "      <td>0.857715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.947336</td>\n",
       "      <td>0.866411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.951173</td>\n",
       "      <td>0.880946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.954053</td>\n",
       "      <td>0.895524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.955010</td>\n",
       "      <td>0.895524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.956924</td>\n",
       "      <td>0.901321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_C  mean_test_accuracy  mean_test_recall\n",
       "0     0.0001            0.926265          0.776343\n",
       "1     0.0010            0.939676          0.817050\n",
       "2     0.0100            0.948293          0.857715\n",
       "3     0.1000            0.947336          0.866411\n",
       "4     1.0000            0.951173          0.880946\n",
       "5    10.0000            0.954053          0.895524\n",
       "6   100.0000            0.955010          0.895524\n",
       "7  1000.0000            0.956924          0.901321"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print CV results\n",
    "cv_result = pd.DataFrame(gscv.cv_results_)\n",
    "cv_result.loc[:,['param_C', 'mean_test_accuracy', 'mean_test_recall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98ea38",
   "metadata": {},
   "source": [
    "The model does not sacrifice accuracy to maximize the recall. Instead, the accuracy increases while we try to maximize recall.\n",
    "\n",
    "The default probability threshold in this SVC model (linear) is 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e44ae4-00e3-4a48-93cf-2e324fb67689",
   "metadata": {},
   "source": [
    "## 3)\n",
    "\n",
    "For a classification model, tuning the model hyperparameters is not enough. The decision threshold needs to be tuned as well, especially for tasks like fraud detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234951d-2bbc-4543-acfe-ee2fa0eee245",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "- For the classification task in this assignment, are False Negatives and False Positives equally important?\n",
    "- If not, which one is more important to avoid? Why?\n",
    "- Which classification metric needs to be maximized (ideally)?\n",
    "\n",
    "**(5 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a98bb0",
   "metadata": {},
   "source": [
    "They are not equally important. In this case related to fraud, false negative means they predict there is no fraudulent action, but in fact the fraud is committed. On the other hand, false negative means they predict that there is fraudulent transaction but in reality no crime is comitted. False negative, which mistakenly leaves out fraudulent transaction, can lead to critical consequences like financial losses or system failure while false positive which falsely perceive the regular transaction to be fraudulent is just annoying but does not contribute to big impacts. Therefore, false negative is more critical.\n",
    "\n",
    "The classification matrix we need to maximize is **recall** since recall increases when false negative decreases. The maximum recall leads to the minimum false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a3254-9473-4701-9f46-3072c52580e3",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "In order to tune the decision threshold, you need to find the cross-validation accuracy and recall for all possible threshold values (with a reasonable granularity).\n",
    "\n",
    "- Start by creating an empty DataFrame with three columns: `thr`, `acc`, and `rec`. You will use this DataFrame to store your results.\n",
    "- Initialize a `counter` variable at 0. You will use this to index the DataFrame to store your results.\n",
    "- Using the `best_estimator_` of the cross-validation in Question 2b, obtain the cross-validation Class 1 probabilities of all observations. You need the `cross_val_predict` function for this; please consider checking the posted notes if you are not familiar with its usage. You also need to keep the same `cv` input as in Question 2, so the results are consistent.\n",
    "- For each threshold value between 0 and 1, with a stepsize of 0.01, calculate the accuracy and recall score when the Class 1 probabilities are converted to class values with the threshold value.\n",
    "- Store the accuracy and recall values of all thresholds in your DataFrame.\n",
    "\n",
    "**Note:** This should take 3-4 minutes to run. You can use the given lines to keep track of the elapsed time. (You do not have to and you can delete those lines if you wish.)\n",
    "\n",
    "**(20 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "197d897c-5678-48c3-b6bf-3a1d432ec9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time:  2.2208179871241254 minutes.\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "########## YOUR CODE HERE #############\n",
    "\n",
    "# Create empty data frame\n",
    "df = pd.DataFrame(columns= ['thr', 'acc', 'rec'])\n",
    "\n",
    "# Initialize counter variable\n",
    "counter = 0\n",
    "\n",
    "# Get the best estimator from the model, find cross val predict prob (Class 1, column 2)\n",
    "probability_class1 = cross_val_predict(gscv.best_estimator_, X_train, y_train, cv = cv_settings, method= 'predict_proba')[:,1]\n",
    "\n",
    "# Set the possible threshold\n",
    "thrs = np.arange(0,1.01,0.01)\n",
    "\n",
    "# Find accuracy and recall of each threshold, store it in dataframe\n",
    "for thr in thrs:\n",
    "    y_pred = (probability_class1 >= thr).astype(int)\n",
    "    df.loc[counter,'thr'] = thr # Set threshold to thr\n",
    "    df.loc[counter,'acc'] = accuracy_score(y_train, y_pred)\n",
    "    df.loc[counter,'rec'] = recall_score(y_train, y_pred)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "#######################################\n",
    "\n",
    "toc = time.time()\n",
    "print('Elapsed Time: ', (toc-tic)/60, 'minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31f86e-5013-4a29-9f9b-468a71e528a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### c)\n",
    "\n",
    "Print all the rows with threshold values that return a perfect recall. Is there a threshold value that returns a reasonable accuracy with the perfect recall? (The word \"reasonable\" sounds subjective, but you should see a clear difference from the accuracy results in Question 2.)\n",
    "\n",
    "**(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "45fc7a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thr</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.331418</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.334291</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.397510</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thr       acc  rec\n",
       "0  0.00  0.329502  1.0\n",
       "1  0.01  0.329502  1.0\n",
       "2  0.02  0.329502  1.0\n",
       "3  0.03  0.329502  1.0\n",
       "4  0.04  0.329502  1.0\n",
       "5  0.05  0.329502  1.0\n",
       "6  0.06  0.329502  1.0\n",
       "7  0.07  0.331418  1.0\n",
       "8  0.08  0.334291  1.0\n",
       "9  0.09  0.397510  1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all the rows that return perfect recall\n",
    "\n",
    "# Convert everything to numeric first (necessary because of sklearn)\n",
    "df = df.astype(float)\n",
    "\n",
    "df.loc[df['rec'] == 1.00]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1925a65",
   "metadata": {},
   "source": [
    "There are ten thresholds value 0.00, 0.01, 0.02, 0.03, ..., 0.09 that returns a perfect recall of 1.0. However, the accuracy is not reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243492f-0b50-4188-aeb7-2ac9e61a64ae",
   "metadata": {},
   "source": [
    "### d)\n",
    "\n",
    "Find the threshold value that returns the highest recall while the accuracy is above 80%. This will be your tuned threshold. **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d32c89a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thr    0.100000\n",
       "acc    0.809387\n",
       "rec    0.869186\n",
       "Name: 10, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the acc > 80 % first\n",
    "df_acc = df.loc[df['acc'] > 0.8]\n",
    "\n",
    "df_acc.rec.idxmax() # Use idx.max instead of arg.max\n",
    "\n",
    "df_acc.loc[df_acc.rec.idxmax(), :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b045a-0725-4f2b-a2d8-8c478fbba427",
   "metadata": {},
   "source": [
    "### e)\n",
    "\n",
    "Using the tuned model from Question 2 and the tuned threshold from Part d in this question, find the test accuracy and recall. Do you observe any overfitting? (This conclusion might be up for debate, so just write what you observe and how you interpret it.)\n",
    "\n",
    "**(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c9d7256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9486607142857143\n",
      "Recall Score: 0.8445945945945946\n"
     ]
    }
   ],
   "source": [
    "# Get the best model and tuned threshold\n",
    "best_model = gscv.best_estimator_\n",
    "threshold = 0.1\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(X_train, y_train) # Use the ENTIRE dataset\n",
    "\n",
    "# Predict and evaluate with test data and the best threshold\n",
    "y_pred = best_model.predict_proba(X_test)[:,1] > threshold\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Recall Score: {recall_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a5668",
   "metadata": {},
   "source": [
    "There is no overfitting since the accuracy score and recall score from the testing data is higher than that of training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
